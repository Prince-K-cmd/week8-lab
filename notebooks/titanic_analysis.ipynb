{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Titanic - Machine Learning from Disaster\n",
    "\n",
    "## Overview\n",
    "\n",
    "This notebook contains a comprehensive analysis of the Titanic dataset, implementing various machine learning techniques to predict passenger survival.\n",
    "\n",
    "## Table of Contents\n",
    "\n",
    "1. [Task 1: Data Exploration and Visualization](#1.-Task-1:-Data-Exploration-and-Visualization)\n",
    "\n",
    "   - Load dataset using DataLoader\n",
    "   - Analyze key statistics\n",
    "   - Visualize relationships using TitanicVisualizer\n",
    "\n",
    "2. [Task 2: Data Cleaning and Preprocessing](#2.-Task-2:-Data-Cleaning-and-Preprocessing)\n",
    "\n",
    "   - Handle missing values using FeatureProcessor\n",
    "   - Encode categorical variables\n",
    "   - Scale features\n",
    "   - Split dataset\n",
    "\n",
    "3. [Task 3: Feature Engineering](#3.-Task-3:-Feature-Engineering)\n",
    "\n",
    "   - Generate new features using FeatureProcessor\n",
    "   - Perform feature selection\n",
    "   - Analyze feature importance\n",
    "\n",
    "4. [Task 4: Model Selection and Training](#4.-Task-4:-Model-Selection-and-Training)\n",
    "\n",
    "   - Train multiple models\n",
    "   - Use cross-validation\n",
    "   - Compare models using multiple metrics\n",
    "\n",
    "5. [Task 5: Model Optimization](#5.-Task-5:-Model-Optimization)\n",
    "\n",
    "   - Perform hyperparameter tuning\n",
    "   - Evaluate optimized models\n",
    "\n",
    "6. [Task 6: Testing and Submission](#6.-Task-6:-Testing-and-Submission)\n",
    "   - Make predictions on test set\n",
    "   - Generate submission file\n",
    "\n",
    "## Setup\n",
    "\n",
    "First, let's import all necessary libraries and initialize our processors.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add src directory to Python path\n",
    "import sys\n",
    "sys.path.append('..')\n",
    "\n",
    "# Data manipulation and analysis\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Machine Learning\n",
    "from sklearn.model_selection import cross_val_score, GridSearchCV, RandomizedSearchCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score\n",
    "from sklearn.metrics import classification_report, confusion_matrix, roc_curve, auc\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Custom modules\n",
    "from src.data_processing import DataLoader, FeatureProcessor, TitanicPreprocessor, ModelEvaluator\n",
    "from src.visualization import TitanicVisualizer\n",
    "\n",
    "# Initialize processors\n",
    "data_loader = DataLoader()\n",
    "feature_processor = FeatureProcessor()\n",
    "preprocessor = TitanicPreprocessor()\n",
    "visualizer = TitanicVisualizer()\n",
    "model_evaluator = ModelEvaluator(visualizer)\n",
    "\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create paths to files or data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set base path for data\n",
    "base_path = '../data/raw/'\n",
    "\n",
    "# Construct the full path to the training dataset\n",
    "train_data_path = base_path + 'train.csv'\n",
    "\n",
    "# Construct the full path to the test dataset\n",
    "test_data_path = base_path + 'test.csv'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Task 1: Data Exploration and Visualization\n",
    "\n",
    "## 1.1 Load Dataset using DataLoader\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set shape: (712, 12)\n",
      "Test set shape: (179, 11)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "      <th>Survived</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>693</td>\n",
       "      <td>3</td>\n",
       "      <td>Lam, Mr. Ali</td>\n",
       "      <td>male</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1601</td>\n",
       "      <td>56.4958</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>482</td>\n",
       "      <td>2</td>\n",
       "      <td>Frost, Mr. Anthony Wood \"Archie\"</td>\n",
       "      <td>male</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>239854</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>528</td>\n",
       "      <td>1</td>\n",
       "      <td>Farthing, Mr. John</td>\n",
       "      <td>male</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17483</td>\n",
       "      <td>221.7792</td>\n",
       "      <td>C95</td>\n",
       "      <td>S</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>856</td>\n",
       "      <td>3</td>\n",
       "      <td>Aks, Mrs. Sam (Leah Rosen)</td>\n",
       "      <td>female</td>\n",
       "      <td>18.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>392091</td>\n",
       "      <td>9.3500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>802</td>\n",
       "      <td>2</td>\n",
       "      <td>Collyer, Mrs. Harvey (Charlotte Annie Tate)</td>\n",
       "      <td>female</td>\n",
       "      <td>31.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>C.A. 31921</td>\n",
       "      <td>26.2500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Pclass                                         Name     Sex  \\\n",
       "0          693       3                                 Lam, Mr. Ali    male   \n",
       "1          482       2             Frost, Mr. Anthony Wood \"Archie\"    male   \n",
       "2          528       1                           Farthing, Mr. John    male   \n",
       "3          856       3                   Aks, Mrs. Sam (Leah Rosen)  female   \n",
       "4          802       2  Collyer, Mrs. Harvey (Charlotte Annie Tate)  female   \n",
       "\n",
       "    Age  SibSp  Parch      Ticket      Fare Cabin Embarked  Survived  \n",
       "0   NaN      0      0        1601   56.4958   NaN        S         1  \n",
       "1   NaN      0      0      239854    0.0000   NaN        S         0  \n",
       "2   NaN      0      0    PC 17483  221.7792   C95        S         0  \n",
       "3  18.0      0      1      392091    9.3500   NaN        S         1  \n",
       "4  31.0      1      1  C.A. 31921   26.2500   NaN        S         1  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Load raw data using DataLoader\n",
    "train_data = data_loader.load_csv(train_data_path)\n",
    "test_data = data_loader.load_csv(test_data_path)\n",
    "\n",
    "print(\"Training set shape:\", train_data.shape)\n",
    "print(\"Test set shape:\", test_data.shape)\n",
    "\n",
    "# Display first few rows\n",
    "display(train_data.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2 Analyze Key Statistics\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Basic Statistics:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Survived</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>712.000000</td>\n",
       "      <td>712.000000</td>\n",
       "      <td>575.000000</td>\n",
       "      <td>712.000000</td>\n",
       "      <td>712.000000</td>\n",
       "      <td>712.000000</td>\n",
       "      <td>712.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>444.405899</td>\n",
       "      <td>2.308989</td>\n",
       "      <td>29.807687</td>\n",
       "      <td>0.492978</td>\n",
       "      <td>0.390449</td>\n",
       "      <td>31.819826</td>\n",
       "      <td>0.383427</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>257.465527</td>\n",
       "      <td>0.833563</td>\n",
       "      <td>14.485211</td>\n",
       "      <td>1.060720</td>\n",
       "      <td>0.838134</td>\n",
       "      <td>48.059104</td>\n",
       "      <td>0.486563</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.420000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>222.750000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>21.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>7.895800</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>439.500000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>28.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>14.454200</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>667.250000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>39.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>31.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>891.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>80.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>512.329200</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       PassengerId      Pclass         Age       SibSp       Parch  \\\n",
       "count   712.000000  712.000000  575.000000  712.000000  712.000000   \n",
       "mean    444.405899    2.308989   29.807687    0.492978    0.390449   \n",
       "std     257.465527    0.833563   14.485211    1.060720    0.838134   \n",
       "min       1.000000    1.000000    0.420000    0.000000    0.000000   \n",
       "25%     222.750000    2.000000   21.000000    0.000000    0.000000   \n",
       "50%     439.500000    3.000000   28.500000    0.000000    0.000000   \n",
       "75%     667.250000    3.000000   39.000000    1.000000    0.000000   \n",
       "max     891.000000    3.000000   80.000000    8.000000    6.000000   \n",
       "\n",
       "             Fare    Survived  \n",
       "count  712.000000  712.000000  \n",
       "mean    31.819826    0.383427  \n",
       "std     48.059104    0.486563  \n",
       "min      0.000000    0.000000  \n",
       "25%      7.895800    0.000000  \n",
       "50%     14.454200    0.000000  \n",
       "75%     31.000000    1.000000  \n",
       "max    512.329200    1.000000  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dataset Info:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 712 entries, 0 to 711\n",
      "Data columns (total 12 columns):\n",
      " #   Column       Non-Null Count  Dtype  \n",
      "---  ------       --------------  -----  \n",
      " 0   PassengerId  712 non-null    int64  \n",
      " 1   Pclass       712 non-null    int64  \n",
      " 2   Name         712 non-null    object \n",
      " 3   Sex          712 non-null    object \n",
      " 4   Age          575 non-null    float64\n",
      " 5   SibSp        712 non-null    int64  \n",
      " 6   Parch        712 non-null    int64  \n",
      " 7   Ticket       712 non-null    object \n",
      " 8   Fare         712 non-null    float64\n",
      " 9   Cabin        160 non-null    object \n",
      " 10  Embarked     710 non-null    object \n",
      " 11  Survived     712 non-null    int64  \n",
      "dtypes: float64(2), int64(5), object(5)\n",
      "memory usage: 66.9+ KB\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "None"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Missing Values:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Age         137\n",
       "Cabin       552\n",
       "Embarked      2\n",
       "dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Display basic statistics\n",
    "print(\"\\nBasic Statistics:\")\n",
    "display(train_data.describe())\n",
    "\n",
    "# Display info about data types and missing values\n",
    "print(\"\\nDataset Info:\")\n",
    "display(train_data.info())\n",
    "\n",
    "# Calculate missing values\n",
    "missing_values = train_data.isnull().sum()\n",
    "print(\"\\nMissing Values:\")\n",
    "display(missing_values[missing_values > 0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.3 Visualize Relationships using TitanicVisualizer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create directory for plots\n",
    "import os\n",
    "plots_dir = '../plots'\n",
    "os.makedirs(plots_dir, exist_ok=True)\n",
    "\n",
    "# Plot survival rates by various features\n",
    "for feature in ['Sex', 'Pclass', 'Embarked']:\n",
    "    visualizer.plot_survival_by_feature(train_data, feature)\n",
    "\n",
    "# Plot age distribution\n",
    "visualizer.plot_age_distribution(train_data)\n",
    "\n",
    "# Plot correlation matrix for numerical features\n",
    "numeric_data = train_data.select_dtypes(include=[np.number])\n",
    "visualizer.plot_correlation_matrix(numeric_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Task 2: Data Cleaning and Preprocessing\n",
    "\n",
    "## 2.1 Handle Missing Values using FeatureProcessor\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing values after handling:\n",
      "Cabin    552\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Handle missing values\n",
    "train_clean = feature_processor.handle_missing_values(train_data)\n",
    "test_clean = feature_processor.handle_missing_values(test_data)\n",
    "\n",
    "print(\"Missing values after handling:\")\n",
    "print(train_clean.isnull().sum()[train_clean.isnull().sum() > 0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2 Feature Engineering and Encoding\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features after preprocessing:\n",
      "['PassengerId', 'Pclass', 'Age', 'SibSp', 'Parch', 'Fare', 'Survived', 'HasCabin', 'FamilySize', 'IsAlone', 'FarePerPerson', 'Sex_male', 'Embarked_Q', 'Embarked_S', 'Title_Miss', 'Title_Mr', 'Title_Mrs', 'Title_Rare', 'Deck_B', 'Deck_C', 'Deck_D', 'Deck_E', 'Deck_F', 'Deck_G', 'Deck_T', 'Deck_Unknown', 'AgeGroup_Teenager', 'AgeGroup_Young Adult', 'AgeGroup_Adult', 'AgeGroup_Senior', 'AgeGroup_Elderly']\n"
     ]
    }
   ],
   "source": [
    "# Create new features\n",
    "train_featured = feature_processor.create_features(train_clean)\n",
    "test_featured = feature_processor.create_features(test_clean)\n",
    "\n",
    "# Encode categorical variables\n",
    "categorical_features = ['Sex', 'Embarked', 'Title', 'Deck', 'AgeGroup']\n",
    "train_encoded = feature_processor.encode_categorical_features(train_featured, categorical_features)\n",
    "test_encoded = feature_processor.encode_categorical_features(test_featured, categorical_features)\n",
    "\n",
    "# Scale features\n",
    "features_to_scale = ['Age', 'Fare', 'FarePerPerson']\n",
    "train_scaled = feature_processor.scale_features(train_encoded, features_to_scale)\n",
    "test_scaled = feature_processor.scale_features(test_encoded, features_to_scale)\n",
    "\n",
    "print(\"Features after preprocessing:\")\n",
    "print(train_scaled.columns.tolist())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.3 Prepare Final Dataset using TitanicPreprocessor\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set shape: (569, 1746)\n",
      "Validation set shape: (143, 1746)\n",
      "Test set shape: (179, 1746)\n"
     ]
    }
   ],
   "source": [
    "# Process data using our optimized pipeline\n",
    "processed_data = preprocessor.prepare_data(\n",
    "    train_path=train_data_path,\n",
    "    test_path=test_data_path,\n",
    "    test_size=0.2,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "X_train = processed_data['X_train']\n",
    "X_val = processed_data['X_val']\n",
    "y_train = processed_data['y_train']\n",
    "y_val = processed_data['y_val']\n",
    "test_processed = processed_data['test_processed']\n",
    "\n",
    "print(\"Training set shape:\", X_train.shape)\n",
    "print(\"Validation set shape:\", X_val.shape)\n",
    "print(\"Test set shape:\", test_processed.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Task 3: Feature Engineering\n",
    "\n",
    "## 3.1 Analyze Feature Importance\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Check plots in the 'plots' directory.\n"
     ]
    }
   ],
   "source": [
    "# Train a Random Forest for feature importance\n",
    "rf_model = RandomForestClassifier(random_state=42)\n",
    "\n",
    "# Create dummy variables for categorical columns\n",
    "X_train_encoded = X_train.copy()\n",
    "categorical_columns = ['AgeGroup', 'Title', 'Deck', 'Sex', 'Embarked']\n",
    "numeric_columns = X_train.select_dtypes(include=['int64', 'float64']).columns\n",
    "\n",
    "# Keep numeric columns as is\n",
    "X_train_final = X_train_encoded[numeric_columns].copy()\n",
    "\n",
    "# Create dummies for categorical columns\n",
    "for column in categorical_columns:\n",
    "    if column in X_train.columns:  # Only process if column exists\n",
    "        # Create dummy variables and drop the first category to avoid multicollinearity\n",
    "        dummies = pd.get_dummies(X_train[column], prefix=column, drop_first=True)\n",
    "        # Add the dummy columns to the dataset\n",
    "        X_train_final = pd.concat([X_train_final, dummies], axis=1)\n",
    "\n",
    "# Fit the model to the data (y_train should already be encoded)\n",
    "rf_model.fit(X_train_final, y_train)\n",
    "\n",
    "# Create feature importance DataFrame\n",
    "feature_importance = pd.DataFrame({\n",
    "    'Feature': X_train_final.columns,\n",
    "    'Importance': rf_model.feature_importances_\n",
    "}).sort_values('Importance', ascending=False)\n",
    "\n",
    "# Plot feature importance\n",
    "visualizer.plot_feature_importance(feature_importance)\n",
    "print(\"Check plots in the 'plots' directory.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Task 4: Model Selection and Training\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Logistic Regression...\n",
      "Cross-validation scores: [0.84210526 0.84210526 0.8245614  0.80701754 0.80530973]\n",
      "Mean CV score: 0.824 (+/- 0.032)\n",
      "Training Random Forest...\n",
      "Cross-validation scores: [0.83333333 0.78947368 0.81578947 0.78070175 0.82300885]\n",
      "Mean CV score: 0.808 (+/- 0.040)\n",
      "Training SVM...\n",
      "Cross-validation scores: [0.83333333 0.84210526 0.78947368 0.78947368 0.83185841]\n",
      "Mean CV score: 0.817 (+/- 0.046)\n",
      "\n",
      "Model Performance:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Logistic Regression</th>\n",
       "      <th>Random Forest</th>\n",
       "      <th>SVM</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>accuracy</th>\n",
       "      <td>0.832</td>\n",
       "      <td>0.804</td>\n",
       "      <td>0.804</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>precision</th>\n",
       "      <td>0.792</td>\n",
       "      <td>0.865</td>\n",
       "      <td>0.729</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>recall</th>\n",
       "      <td>0.764</td>\n",
       "      <td>0.582</td>\n",
       "      <td>0.782</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f1</th>\n",
       "      <td>0.778</td>\n",
       "      <td>0.696</td>\n",
       "      <td>0.754</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>roc_auc</th>\n",
       "      <td>0.850</td>\n",
       "      <td>0.842</td>\n",
       "      <td>0.858</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Logistic Regression  Random Forest    SVM\n",
       "accuracy                 0.832          0.804  0.804\n",
       "precision                0.792          0.865  0.729\n",
       "recall                   0.764          0.582  0.782\n",
       "f1                       0.778          0.696  0.754\n",
       "roc_auc                  0.850          0.842  0.858"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Check plots in the 'plots' directory.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Define custom models with optimized parameters\n",
    "custom_models = {\n",
    "    'Logistic Regression': LogisticRegression(\n",
    "        random_state=42,\n",
    "        max_iter=1000,  # Increased iterations\n",
    "        C=0.1  # Add regularization\n",
    "    ),\n",
    "    'Random Forest': RandomForestClassifier(\n",
    "        random_state=42,\n",
    "        n_estimators=200,\n",
    "        max_depth=10\n",
    "    ),\n",
    "    'SVM': SVC(\n",
    "        probability=True,\n",
    "        random_state=42,\n",
    "        C=1.0,\n",
    "        kernel='rbf',\n",
    "        class_weight='balanced'\n",
    "    )\n",
    "}\n",
    "\n",
    "# Train and evaluate all models using custom configurations\n",
    "results_df = model_evaluator.evaluate_all_models(\n",
    "    X_train, X_val, y_train, y_val, \n",
    "    models=custom_models\n",
    ")\n",
    "\n",
    "print(\"\\nModel Performance:\")\n",
    "display(results_df)\n",
    "print(\"Check plots in the 'plots' directory.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Task 5: Model Optimization\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Optimizing Logistic Regression...\n",
      "Best parameters: {'C': 10, 'penalty': 'l2', 'solver': 'liblinear'}\n",
      "Best cross-validation score: 0.835\n",
      "\n",
      "Optimizing Random Forest...\n",
      "Best parameters: {'max_depth': None, 'min_samples_leaf': 1, 'min_samples_split': 10, 'n_estimators': 300}\n",
      "Best cross-validation score: 0.840\n",
      "\n",
      "Optimizing SVM...\n",
      "Best parameters: {'C': 1, 'gamma': 'scale', 'kernel': 'linear'}\n",
      "Best cross-validation score: 0.837\n",
      "\n",
      "Optimized Model Performance:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Logistic Regression</th>\n",
       "      <th>Random Forest</th>\n",
       "      <th>SVM</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>accuracy</th>\n",
       "      <td>0.818</td>\n",
       "      <td>0.825</td>\n",
       "      <td>0.832</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>precision</th>\n",
       "      <td>0.764</td>\n",
       "      <td>0.778</td>\n",
       "      <td>0.792</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>recall</th>\n",
       "      <td>0.764</td>\n",
       "      <td>0.764</td>\n",
       "      <td>0.764</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f1</th>\n",
       "      <td>0.764</td>\n",
       "      <td>0.771</td>\n",
       "      <td>0.778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>roc_auc</th>\n",
       "      <td>0.892</td>\n",
       "      <td>0.860</td>\n",
       "      <td>0.903</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Logistic Regression  Random Forest    SVM\n",
       "accuracy                 0.818          0.825  0.832\n",
       "precision                0.764          0.778  0.792\n",
       "recall                   0.764          0.764  0.764\n",
       "f1                       0.764          0.771  0.778\n",
       "roc_auc                  0.892          0.860  0.903"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# * set as default models in the data_processing.py file\n",
    "# custom_models = {\n",
    "#     'Logistic Regression': LogisticRegression(random_state=42),\n",
    "#     'Random Forest': RandomForestClassifier(random_state=42),\n",
    "#     'SVM': SVC(probability=True, random_state=42)\n",
    "# }\n",
    "\n",
    "\n",
    "optimized_df, optimized_models = model_evaluator.perform_grid_search(\n",
    "    X_train, X_val, y_train, y_val,\n",
    ")\n",
    "\n",
    "print(\"\\nOptimized Model Performance:\")\n",
    "display(optimized_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. Task 6: Testing and Submission\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best model: SVM\n",
      "Submission file saved to: ..\\submissions\\Prince2_submission.csv\n",
      "\n",
      "Sample predictions:\n",
      "   PassengerId  Survived\n",
      "0        566.0         0\n",
      "1        161.0         0\n",
      "2        554.0         0\n",
      "3        861.0         0\n",
      "4        242.0         0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "WindowsPath('../submissions/Prince2_submission.csv')"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# Get best model and make predictions\n",
    "best_model_name, submission = model_evaluator.get_best_model_and_predict(\n",
    "    optimized_df, optimized_models, test_processed\n",
    ")\n",
    "\n",
    "# Save submission file\n",
    "filename = 'Prince_submission.csv'\n",
    "model_evaluator.save_submission(submission, filename=filename)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
